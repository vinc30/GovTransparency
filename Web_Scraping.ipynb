{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personal_url(u):\n",
    "\n",
    "    user_url = urlopen(str(u))\n",
    "    soup = BeautifulSoup(user_url, 'html.parser')\n",
    "    \n",
    "    personal_page_url = []\n",
    "    for i in soup.find('div', {'id' : 'box01'}).find_all('a', href = True):\n",
    "        personal_page_url.append(str('https://lis.ly.gov.tw')+ str(i['href']))\n",
    "    return personal_page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 'https://lis.ly.gov.tw/lylegismc/lylegismemkmout?!!FUNC400'\n",
    "personal_url = get_personal_url(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del personal_url[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del personal_url[124]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 個人頁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#問政成果-主頁\n",
    "res = []\n",
    "#問政統計\n",
    "sta = []\n",
    "for u in personal_url:\n",
    "    user_url = urlopen(u)\n",
    "    soup = BeautifulSoup(user_url, 'html.parser')\n",
    "    \n",
    "    temp_ = []\n",
    "    \n",
    "    \n",
    "    for i in soup.find('td', class_ = 'person_t02').find_all('a', href = True):\n",
    "        temp_.append(str('https://lis.ly.gov.tw')+ str(i['href']))\n",
    "    \n",
    "    #collect list of url for 問政成果\n",
    "    res.append(temp_[1])\n",
    "    #collect list of url for 問政統計\n",
    "    sta.append(temp_[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問政成果-委員諮詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#問政成果-委員諮詢\n",
    "res_advisory = []\n",
    "\n",
    "for u in res:\n",
    "    user_url = urlopen(u)\n",
    "    soup = BeautifulSoup(user_url, 'html.parser')\n",
    "    \n",
    "    if len(soup.find('div', attrs={\"class\":\"pop\",\"id\":\"pop02\"}).find_all('a', href = True)):\n",
    "        res_advisory.append(' ')\n",
    "    else:\n",
    "        for i in soup.find('div', attrs={\"class\":\"pop\",\"id\":\"pop02\"}).find_all('a', href = True):\n",
    "            res_advisory.append(str('https://lis.ly.gov.tw')+ str(i['href']))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = []\n",
    "case_url = []\n",
    "idx = 0\n",
    "for u in res_advisory:\n",
    "    \n",
    "    if u != ' ':\n",
    "        user_url = urlopen(u)\n",
    "        soup = BeautifulSoup(user_url, 'html.parser')\n",
    "\n",
    "        #質詢日期\n",
    "        for i in soup.find('table', class_ = 'sumtab').find_all('td', class_ = 'sumtd2000'):\n",
    "            date_list.append([idx, i.get_text().strip()])\n",
    "\n",
    "        #案由\n",
    "        table = soup.find('table', class_ = 'sumtab')\n",
    "        rows = table.find_all('td', class_ ='sumtd2001')\n",
    "        for row in rows:\n",
    "            cols = row.find_all('a')\n",
    "            for col in cols:\n",
    "                case_url.append([idx, str('https://lis.ly.gov.tw')+ str(col['href'])]) \n",
    "    else:\n",
    "\n",
    "        date_list.append('')\n",
    "        case_url.append('')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(date_list))\n",
    "print(len(case_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(date_list, columns = ['idx', 'date'])\n",
    "b = pd.DataFrame(case_url, columns = ['idx1', 'case_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.merge(a, b, left_index= True, right_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.set_index('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'main_page_url': personal_url, 'result_url': res, 'result_advisory_url': res_advisory, 'statistic': sta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df.merge(c, left_on = 'index', right_on = 'idx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_f['idx']\n",
    "del df_f['idx1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問政成果-詳細資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手動輸入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入url\n",
    "u = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_url = []\n",
    "user_url = urlopen(u)\n",
    "soup = BeautifulSoup(user_url, 'html.parser')\n",
    "\n",
    "table = soup.find('td', attrs={'class':'disp62_m'})\n",
    "temp = table.find('td', attrs={'class':'dettb02'}).get_text()\n",
    "\n",
    "\n",
    "#name\n",
    "try:\n",
    "    name = temp.split('\\n')[0]\n",
    "except IndexError:\n",
    "    name = ' '\n",
    "\n",
    "#property\n",
    "try:\n",
    "    propty = temp.split('\\n')[1][4:]\n",
    "except IndexError:\n",
    "    property = ' '\n",
    "\n",
    "#inquiry\n",
    "try:\n",
    "    inqry =  temp.split('\\n')[2][2:]\n",
    "except IndexError:\n",
    "    inqry = ' '\n",
    "\n",
    "# case \n",
    "try:\n",
    "    case = temp.split('\\n')[3][2:]\n",
    "except IndexError:\n",
    "    case = ' '\n",
    "\n",
    "#reply_check\n",
    "try:\n",
    "    reply_chk = temp.split('\\n')[4][3:]\n",
    "except IndexError:\n",
    "    reply_chk = ' '\n",
    "\n",
    "    #reply\n",
    "try:\n",
    "    reply = temp.split('\\n')[5][2:]\n",
    "except IndexError:\n",
    "    reply = ' '\n",
    "\n",
    "#people_reply\n",
    "try:\n",
    "    ppl_reply = temp.split('\\n')[6][3:]\n",
    "except IndexError:\n",
    "    ppl_reply = ' '\n",
    "\n",
    "#date_inquiry\n",
    "try:\n",
    "    date_inqry = temp.split('\\n')[7][4:]\n",
    "except IndexError:\n",
    "    date_inqry = ' '\n",
    "\n",
    "#reply date\n",
    "try:\n",
    "    date_reply = temp.split('\\n')[8][4:]\n",
    "except IndexError:\n",
    "    date_reply = ' '\n",
    "\n",
    "#system no\n",
    "try:\n",
    "    sys_no = temp.split('\\n')[9][3:]\n",
    "except IndexError:\n",
    "    sys_no = ' '\n",
    "\n",
    "#category\n",
    "try:\n",
    "    ctgry = temp.split('\\n')[10][2:]\n",
    "except IndexError:\n",
    "    ctgry = ' '\n",
    "\n",
    "#keyword\n",
    "try:\n",
    "    keyword = temp.split('\\n')[11][3:]\n",
    "except IndexError:\n",
    "    keyword = ' '\n",
    "\n",
    "#pdf link\n",
    "try:\n",
    "    link_ = table.find_all('a', attrs = {'title':\"PDF文字型電子檔\"}, href = True)[0]\n",
    "    pdf_link = str('https://lis.ly.gov.tw')+ str(link_['href'])\n",
    "except IndexError:    \n",
    "    pdf_link = ''\n",
    "\n",
    "    \n",
    "col_header =['name', 'property', 'inquiry', 'case', 'reply_check', 'reply', 'people_reply', 'date_inquiry', 'date_reply', 'sys_no',\n",
    "      'category', 'keyword', 'pdf_link'] \n",
    "    \n",
    "sec_list.append([name, propty, inqry, case, reply_chk, reply, ppl_reply, date_inqry, date_reply, sys_no,\n",
    "      ctgry, keyword, pdf_link])\n",
    "temp_url = pdf_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_pdf(url, path, fn):\n",
    "    '''\n",
    "    url the url link for pdf\n",
    "    path to save the file to e.g. /Docs/test.pdf\n",
    "    '''\n",
    "    r = requests.get(url, stream=True)\n",
    "    chunk_size = 24\n",
    "    if path == None:\n",
    "        _path = fn + '.pdf'\n",
    "    else:\n",
    "        _path = os.path.join(path, fn + '.pdf')\n",
    "        \n",
    "    print (_path)\n",
    "    with open(_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "download_pdf(temp_url, None,  'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://lis.ly.gov.tw/lylegisc/lylegiskmout?000889AB0014010300000000000501400000003D000000000^IMG_lypdftxt_1^xdd!cecac8cccbcfcbc9cacd81cecfc8cfc7cdcfcec4cfcfc8c8c4cfcfc7cf'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sec_list, columns = col_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =================截止=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_list = []\n",
    "\n",
    "for u in df_f['case_url']:\n",
    "    user_url = urlopen(u)\n",
    "    soup = BeautifulSoup(user_url, 'html.parser')\n",
    "\n",
    "    table = soup.find('td', attrs={'class':'disp62_m'})\n",
    "    temp = table.find('td', attrs={'class':'dettb02'}).get_text()\n",
    "\n",
    "\n",
    "    #name\n",
    "    try:\n",
    "        name = temp.split('\\n')[0]\n",
    "    except IndexError:\n",
    "        name = ' '\n",
    "\n",
    "    #property\n",
    "    try:\n",
    "        propty = temp.split('\\n')[1][4:]\n",
    "    except IndexError:\n",
    "        property = ' '\n",
    "\n",
    "    #inquiry\n",
    "    try:\n",
    "        inqry =  temp.split('\\n')[2][2:]\n",
    "    except IndexError:\n",
    "        inqry = ' '\n",
    "\n",
    "    # case \n",
    "    try:\n",
    "        case = temp.split('\\n')[3][2:]\n",
    "    except IndexError:\n",
    "        case = ' '\n",
    "\n",
    "    #reply_check\n",
    "    try:\n",
    "        reply_chk = temp.split('\\n')[4][3:]\n",
    "    except IndexError:\n",
    "        reply_chk = ' '\n",
    "\n",
    "        #reply\n",
    "    try:\n",
    "        reply = temp.split('\\n')[5][2:]\n",
    "    except IndexError:\n",
    "        reply = ' '\n",
    "\n",
    "    #people_reply\n",
    "    try:\n",
    "        ppl_reply = temp.split('\\n')[6][3:]\n",
    "    except IndexError:\n",
    "        ppl_reply = ' '\n",
    "\n",
    "    #date_inquiry\n",
    "    try:\n",
    "        date_inqry = temp.split('\\n')[7][4:]\n",
    "    except IndexError:\n",
    "        date_inqry = ' '\n",
    "\n",
    "    #reply date\n",
    "    try:\n",
    "        date_reply = temp.split('\\n')[8][4:]\n",
    "    except IndexError:\n",
    "        date_reply = ' '\n",
    "\n",
    "    #system no\n",
    "    try:\n",
    "        sys_no = temp.split('\\n')[9][3:]\n",
    "    except IndexError:\n",
    "        sys_no = ' '\n",
    "\n",
    "    #category\n",
    "    try:\n",
    "        ctgry = temp.split('\\n')[10][2:]\n",
    "    except IndexError:\n",
    "        ctgry = ' '\n",
    "\n",
    "    #keyword\n",
    "    try:\n",
    "        keyword = temp.split('\\n')[11][3:]\n",
    "    except IndexError:\n",
    "        keyword = ' '\n",
    "\n",
    "    #pdf link\n",
    "    try:\n",
    "        link_ = table.find_all('a', attrs = {'title':\"PDF文字型電子檔\"}, href = True)[0]\n",
    "        pdf_link = str('https://lis.ly.gov.tw')+ str(link_['href'])\n",
    "    except IndexError:\n",
    "        pdf_link = ' '\n",
    "        \n",
    "    sec_list.append([name, propty, inqry, case, reply_chk, reply, ppl_reply, date_inqry, date_reply, sys_no,\n",
    "          ctgry, keyword, pdf_link])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sec = pd.DataFrame(sec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sec.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提案類別統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 'https://lis.ly.gov.tw/lylegisc/lylegiskmout?.066300A7000000000001000^000000E0000E1000000000000074713eb5'\n",
    "user_url = urlopen(u)\n",
    "soup = BeautifulSoup(user_url, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table', attrs = {'class': 'column_list', 'id': 'lgmempro_class_data' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry = []\n",
    "for i in table.find_all('th'):\n",
    "    industry.append(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = []\n",
    "for i in table.find_all('td'):\n",
    "    num.append(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(industry, num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 進度統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table', attrs = {'class': 'pie_list', 'id': 'lgmempro_progress_data' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = []\n",
    "for i in table.find_all('td', attrs = {'class':'', 'style': ''}):\n",
    "    progress.append(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for i in table.find_all('td', attrs = {'class':'total'}):\n",
    "    count.append(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
